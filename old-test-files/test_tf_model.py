import numpy as np
import pandas as pd
import pickle
import tensorflow as tf
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class TensorFlowModelTester:
    """ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ TensorFlow Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
    
    def __init__(self, model_path='model_tf.h5', tokenizer_path='tokenizer_tf.pkl'):
        self.model = None
        self.vectorizer = None
        self.model_path = model_path
        self.tokenizer_path = tokenizer_path

    def load_model_and_vectorizer(self):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°"""
        try:
            print(f"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {self.model_path}...")
            self.model = tf.keras.models.load_model(self.model_path)

            print(f"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°: {self.tokenizer_path}...")
            with open(self.tokenizer_path, 'rb') as f:
                self.vectorizer = pickle.load(f)
                
            print("âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹!")
            return True
            
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸: {e}")
            return False
    
    def predict_text(self, text):
        """ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°"""
        if self.model is None or self.vectorizer is None:
            raise ValueError("ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°!")
        
        # Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ‚ĞµĞºÑÑ‚Ğ°
        text_tfidf = self.vectorizer.transform([text])
        text_dense = text_tfidf.toarray()
        
        # ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ
        prediction_proba = self.model.predict(text_dense, verbose=0)[0][0]
        prediction_class = int(prediction_proba > 0.5)
        
        return {
            'text': text,
            'probability': float(prediction_proba),
            'prediction': prediction_class,
            'label': 'Ğ¢Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ğ¹' if prediction_class == 1 else 'ĞĞµÑ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ğ¹',
            'confidence': f"{prediction_proba*100:.1f}%" if prediction_class == 1 else f"{(1-prediction_proba)*100:.1f}%"
        }
    
    def test_multiple_texts(self, texts):
        """Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¿Ğ¸ÑĞºĞ° Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²"""
        results = []
        
        print(f"ğŸ§ª Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ {len(texts)} ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²...")
        print("=" * 80)
        
        for i, text in enumerate(texts, 1):
            result = self.predict_text(text)
            results.append(result)
            
            # ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
            emoji = "ğŸ”´" if result['prediction'] == 1 else "ğŸŸ¢"
            print(f"{emoji} Ğ¢ĞµÑÑ‚ {i:2d} | {result['label']:12} | {result['confidence']:6} | {text[:60]}...")
            
        return results
    
    def get_statistics(self, results):
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        total = len(results)
        toxic_count = sum(1 for r in results if r['prediction'] == 1)
        non_toxic_count = total - toxic_count
        
        avg_toxic_prob = np.mean([r['probability'] for r in results if r['prediction'] == 1]) if toxic_count > 0 else 0
        avg_non_toxic_prob = np.mean([1 - r['probability'] for r in results if r['prediction'] == 0]) if non_toxic_count > 0 else 0
        
        return {
            'total': total,
            'toxic': toxic_count,
            'non_toxic': non_toxic_count,
            'toxic_percentage': (toxic_count / total) * 100,
            'avg_toxic_confidence': avg_toxic_prob,
            'avg_non_toxic_confidence': avg_non_toxic_prob
        }

def main():
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
    print("ğŸš€ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ• ĞœĞĞ”Ğ•Ğ›Ğ˜ TENSORFLOW")
    print("=" * 50)
    print(f"ğŸ“… Ğ’Ñ€ĞµĞ¼Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
    print("Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:")
    print("1. ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (model_tf.h5)")
    print("2. Ğ”Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (model_tf_2.h5)")

    choice = input("Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ½Ğ¾Ğ¼ĞµÑ€ (1 Ğ¸Ğ»Ğ¸ 2): ").strip()

    if choice == "2":
        tester = TensorFlowModelTester('model_tf_2.h5', '../old_models/tokenizer_tf_2.pkl')
        print("ğŸ“Š Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ° Ğ´Ğ¾Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ")
    else:
        tester = TensorFlowModelTester('../model_tf.h5', 'old_models/tokenizer_tf.pkl')
        print("ğŸ“Š Ğ’Ñ‹Ğ±Ñ€Ğ°Ğ½Ğ° Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ")

    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    if not tester.load_model_and_vectorizer():
        return
    
    # 20 Ñ€Ğ°Ğ·Ğ½Ğ¾Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²
    test_comments = [
        # ĞĞµÑ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸
        "ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ²Ğ°Ñ€, Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ´Ğ¾Ğ²Ğ¾Ğ»ĞµĞ½ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¾Ğ¹! Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒÑ Ğ²ÑĞµĞ¼.",
        "Ğ¡Ğ¿Ğ°ÑĞ¸Ğ±Ğ¾ Ğ·Ğ° Ğ±Ñ‹ÑÑ‚Ñ€ÑƒÑ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºÑƒ. ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ğ²Ñ‹ÑĞ¾Ñ‚Ğµ.",
        "Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ°Ñ Ñ†ĞµĞ½Ğ° Ğ·Ğ° Ñ‚Ğ°ĞºĞ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾. Ğ‘ÑƒĞ´Ñƒ Ğ·Ğ°ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ ĞµÑ‰Ğµ.",
        "Ğ¢Ğ¾Ğ²Ğ°Ñ€ ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ. Ğ£Ğ¿Ğ°ĞºĞ¾Ğ²ĞºĞ° Ğ°ĞºĞºÑƒÑ€Ğ°Ñ‚Ğ½Ğ°Ñ.",
        "ĞÑ‚Ğ·Ñ‹Ğ²Ñ‡Ğ¸Ğ²Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²ĞµÑ†, Ğ¿Ğ¾Ğ¼Ğ¾Ğ³ Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğ¼. ĞœĞ¾Ğ»Ğ¾Ğ´Ñ†Ñ‹!",
        "ĞŸÑ€Ğ¸ÑˆĞ»Ğ¾ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾, Ğ²ÑĞµ Ğ² Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ. Ğ¡Ğ¿Ğ°ÑĞ¸Ğ±Ğ¾ Ğ·Ğ° ÑĞµÑ€Ğ²Ğ¸Ñ.",
        "ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ ÑƒĞ¶Ğµ Ğ¼ĞµÑÑÑ† - Ğ²ÑĞµ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾.",
        "Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğ¹ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½, Ğ²ÑĞµĞ³Ğ´Ğ° Ğ·Ğ°ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ Ğ·Ğ´ĞµÑÑŒ. ĞĞ°Ğ´ĞµĞ¶Ğ½Ğ¾.",
        "Ğ¢Ğ¾Ğ²Ğ°Ñ€ ĞºĞ°Ğº Ğ½Ğ° Ñ„Ğ¾Ñ‚Ğ¾, Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ¿Ğ¾Ğ´Ğ¾ÑˆĞµĞ» Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾.",
        "ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ğµ Ñ†ĞµĞ½Ğ°-ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒÑ.",
        
        # Ğ¢Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸
        "ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚ÑÑ‚Ğ¾Ğ¹! Ğ”ĞµĞ½ÑŒĞ³Ğ¸ Ğ½Ğ° Ğ²ĞµÑ‚ĞµÑ€, Ğ½Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ğ¹Ñ‚Ğµ ÑÑ‚Ğ¾ Ğ´ĞµÑ€ÑŒĞ¼Ğ¾!",
        "Ğ£Ğ¶Ğ°ÑĞ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ²Ğ°Ñ€, Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ²ĞµÑ† Ğ¾Ğ±Ğ¼Ğ°Ğ½Ñ‰Ğ¸Ğº! ĞšĞ¸Ğ´Ğ°ÑÑ‚ Ğ½Ğ° Ğ´ĞµĞ½ÑŒĞ³Ğ¸!",
        "Ğ¤Ñƒ, ĞºĞ°ĞºĞ°Ñ Ğ³Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ! ĞÑ‚Ğ²Ñ€Ğ°Ñ‚Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾, Ğ²ĞµÑ€Ğ½Ğ¸Ñ‚Ğµ Ğ´ĞµĞ½ÑŒĞ³Ğ¸!",
        "Ğ­Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ´ĞµĞ²Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾! Ğ¥ÑƒĞ¶Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ñ Ğ½Ğµ Ğ²Ğ¸Ğ´ĞµĞ»!",
        "ĞœĞ¾ÑˆĞµĞ½Ğ½Ğ¸ĞºĞ¸! ĞŸÑ€Ğ¸ÑĞ»Ğ°Ğ»Ğ¸ Ğ¿Ğ¾Ğ»Ğ½ÑƒÑ Ñ‡ÑƒÑˆÑŒ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°!",
        "Ğ˜Ğ´Ğ¸Ğ¾Ñ‚Ñ‹, Ğ½Ğµ ÑƒĞ¼ĞµÑÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ! Ğ’ÑĞµ ÑĞ»Ğ¾Ğ¼Ğ°Ğ½Ğ¾ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¿Ğ»Ğ¾Ñ…Ğ¾!",
        "ĞĞ°Ğ³Ğ»Ñ‹Ğµ Ğ¾Ğ±Ğ¼Ğ°Ğ½Ñ‰Ğ¸ĞºĞ¸! Ğ¢Ğ¾Ğ²Ğ°Ñ€ Ğ³Ğ¾Ğ²Ğ½Ğ¾, ÑĞµÑ€Ğ²Ğ¸Ñ ĞµÑ‰Ğµ Ñ…ÑƒĞ¶Ğµ!",
        "Ğ”ĞµÑ€ÑŒĞ¼Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½, ĞºĞ¸Ğ´Ğ°ÑÑ‚ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ĞµĞ¹! ĞĞµ ÑĞ²ÑĞ·Ñ‹Ğ²Ğ°Ğ¹Ñ‚ĞµÑÑŒ!",
        "Ğ£Ğ¶Ğ°Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾! Ğ¥Ğ»Ğ°Ğ¼ Ğ·Ğ° Ñ‚Ğ°ĞºĞ¸Ğµ Ğ´ĞµĞ½ÑŒĞ³Ğ¸, ÑÑ‚Ğ¾ Ğ²Ğ¾Ñ€Ğ¾Ğ²ÑÑ‚Ğ²Ğ¾!",
        "ĞŸĞ¾Ğ»Ğ½ĞµĞ¹ÑˆĞ¸Ğ¹ Ğ±Ñ€ĞµĞ´! Ğ’Ñ‹ĞºĞ¸Ğ½ÑƒĞ» Ğ´ĞµĞ½ÑŒĞ³Ğ¸ Ğ½Ğ° ÑÑ‚Ğ¾ ÑƒĞ±Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾!"
    ]
    
    print()
    
    # Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    results = tester.test_multiple_texts(test_comments)
    
    print("\n" + "=" * 80)
    print("ğŸ“Š Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯")
    print("=" * 80)
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ²Ñ‹Ğ²Ğ¾Ğ´ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸
    stats = tester.get_statistics(results)
    
    print(f"ğŸ“ Ğ’ÑĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ²: {stats['total']}")
    print(f"ğŸ”´ Ğ¢Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ñ…: {stats['toxic']} ({stats['toxic_percentage']:.1f}%)")
    print(f"ğŸŸ¢ ĞĞµÑ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ñ…: {stats['non_toxic']} ({100-stats['toxic_percentage']:.1f}%)")
    
    if stats['toxic'] > 0:
        print(f"ğŸ“ˆ Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ñ…: {stats['avg_toxic_confidence']*100:.1f}%")
    if stats['non_toxic'] > 0:
        print(f"ğŸ“ˆ Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ Ğ½ĞµÑ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ñ‹Ñ…: {stats['avg_non_toxic_confidence']*100:.1f}%")
    
    print("\n" + "=" * 80)
    print("ğŸ¯ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğ• Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ«")
    print("=" * 80)
    
    for i, result in enumerate(results, 1):
        status_icon = "ğŸ”´ Ğ¢ĞĞšĞ¡Ğ˜Ğ§ĞĞ«Ğ™  " if result['prediction'] == 1 else "ğŸŸ¢ ĞĞ•Ğ¢ĞĞšĞ¡Ğ˜Ğ§ĞĞ«Ğ™"
        print(f"\n{i:2d}. {status_icon} (ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {result['confidence']})")
        print(f"    ğŸ’¬ \"{result['text']}\"")
        print(f"    ğŸ“Š Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾ĞºÑĞ¸Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸: {result['probability']:.3f}")
    
    print("\n" + "=" * 80)
    print("âœ… Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ• Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ!")
    print("=" * 80)

if __name__ == "__main__":
    main()
