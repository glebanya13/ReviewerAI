#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ò–¢–û–ì–û–í–´–ô –§–ê–ô–õ –û–ë–£–ß–ï–ù–ò–Ø –ù–ï–ô–†–û–°–ï–¢–ò –° RTX 4060
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU, CPU –∏ –û–ó–£ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
"""

import pandas as pd
import numpy as np
import re
import pickle
import os
import time
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_recall_curve, roc_auc_score, precision_score, recall_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import joblib
from concurrent.futures import ThreadPoolExecutor
import multiprocessing
import psutil
import threading
from datetime import datetime, timedelta
from tqdm import tqdm
import sys

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ PyTorch –¥–ª—è GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    from torch.nn import functional as F
    PYTORCH_AVAILABLE = True
    print("‚úÖ PyTorch –¥–æ—Å—Ç—É–ø–µ–Ω - –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è GPU —É—Å–∫–æ—Ä–µ–Ω–∏—è")
except ImportError as e:
    print(f"‚ö†Ô∏è  PyTorch –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    print("üîÑ –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ç–æ–ª—å–∫–æ Scikit-learn")
    PYTORCH_AVAILABLE = False

class SystemMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
    
    def __init__(self):
        self.start_time = time.time()
        self.monitoring = True
        self.monitor_thread = None
        self.current_metrics = {
            'accuracy': 0.0,
            'loss': 0.0,
            'precision': 0.0,
            'recall': 0.0,
            'f1': 0.0
        }
        
    def update_metrics(self, accuracy, loss, precision, recall, f1):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        self.current_metrics = {
            'accuracy': accuracy,
            'loss': loss,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
        
    def get_system_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ"""
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        
        gpu_info = ""
        if PYTORCH_AVAILABLE and torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated(0) / 1024**3
            gpu_max = torch.cuda.max_memory_allocated(0) / 1024**3
            gpu_info = f" | GPU: {gpu_memory:.1f}GB/{torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB (Max: {gpu_max:.1f}GB)"
        
        return f"CPU: {cpu_percent:.1f}% | RAM: {memory.percent:.1f}% ({memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB){gpu_info}"
    
    def get_metrics_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ—Ç—Ä–∏–∫–∞—Ö"""
        return f"Acc: {self.current_metrics['accuracy']:.4f} | Loss: {self.current_metrics['loss']:.4f} | Prec: {self.current_metrics['precision']:.4f} | Rec: {self.current_metrics['recall']:.4f} | F1: {self.current_metrics['f1']:.4f}"
    
    def start_monitoring(self):
        """–ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        def monitor():
            while self.monitoring:
                elapsed = time.time() - self.start_time
                elapsed_str = str(timedelta(seconds=int(elapsed)))
                
                # –û—á–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫—É –∏ –≤—ã–≤–æ–¥–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                sys.stdout.write(f"\r‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed_str} | {self.get_system_info()}")
                sys.stdout.write(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏: {self.get_metrics_info()}")
                sys.stdout.flush()
                time.sleep(2)
        
        self.monitor_thread = threading.Thread(target=monitor, daemon=True)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()

class RTXOptimizedToxicityClassifier:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ —Å RTX 4060"""
    
    def __init__(self):
        self.model = None
        self.vectorizer = None
        self.max_features = 50000  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è RTX 4060
        self.ngram_range = (1, 8)  # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω n-–≥—Ä–∞–º–º
        self.n_jobs = multiprocessing.cpu_count()  # –í—Å–µ —è–¥—Ä–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        self.device = None
        self.monitor = SystemMonitor()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
        self.batch_size = 64  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è GPU
        self.num_workers = self.n_jobs  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU –¥–ª—è RTX 4060
        self.setup_gpu()
        
        print(f"üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –î–õ–Ø RTX 4060")
        print(f"üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {self.max_features}")
        print(f"‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤: {self.n_jobs}")
        print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ SMOTE –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤")
        print(f"üöÄ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–∏—Å—Ç–µ–º—ã")
        print(f"üíæ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size}")
        print(f"üë• –í–æ—Ä–∫–µ—Ä–æ–≤: {self.num_workers}")
    
    def setup_gpu(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU –¥–ª—è RTX 4060"""
        if PYTORCH_AVAILABLE:
            if torch.cuda.is_available():
                self.device = torch.device('cuda')
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                print(f"‚úÖ GPU RTX 4060 –¥–æ—Å—Ç—É–ø–µ–Ω: {gpu_name}")
                print(f"‚úÖ –ü–∞–º—è—Ç—å GPU: {gpu_memory:.1f} GB")
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                torch.backends.cudnn.benchmark = True
                torch.backends.cudnn.deterministic = False
                torch.backends.cuda.matmul.allow_tf32 = True
                torch.backends.cudnn.allow_tf32 = True
                print("‚úÖ CUDA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω—ã")
            else:
                self.device = torch.device('cpu')
                print("‚ö†Ô∏è  GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
        else:
            print("‚ö†Ô∏è  PyTorch –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU")
    
    def preprocess_text(self, text):
        """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ - –¥–∞–Ω–Ω—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã"""
        if pd.isna(text):
            return ""
        return str(text).strip()
    
    def load_data(self, csv_path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
        start_time = time.time()
        
        df = pd.read_csv(csv_path)
        
        print(f"üìä –ö–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: {list(df.columns)}")
        
        if 'text' not in df.columns or 'label' not in df.columns:
            raise ValueError("–í –¥–∞—Ç–∞—Å–µ—Ç–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'text' –∏ 'label'")
        
        print(f"üìà –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        class_counts = df['label'].value_counts()
        print(class_counts)
        
        # –ê–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
        imbalance_ratio = class_counts[0] / class_counts[1]
        print(f"‚ö†Ô∏è  –î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤: {imbalance_ratio:.2f}:1")
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ - –¥–∞–Ω–Ω—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
        print("üîÑ –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É...")
        df['text_processed'] = df['text'].apply(self.preprocess_text)
        
        df = df[df['text_processed'].str.len() > 0]
        
        print(f"‚úÖ –ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Å—Ç–∞–ª–æ—Å—å {len(df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {time.time() - start_time:.2f} —Å–µ–∫")
        
        return df
    
    def prepare_data(self, df):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        print("üîÑ –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏...")
        start_time = time.time()
        
        X = df['text_processed'].values
        y = df['label'].values
        
        # –°–æ–∑–¥–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä
        self.vectorizer = TfidfVectorizer(
            max_features=self.max_features,
            ngram_range=self.ngram_range,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
            min_df=1,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞
            max_df=0.95,  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä
            stop_words=None,
            lowercase=False,  # –î–∞–Ω–Ω—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            strip_accents=None,  # –î–∞–Ω–Ω—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            analyzer='word',
            token_pattern=r'\b\w+\b',  # –ë–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
            sublinear_tf=True,  # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            norm='l2',  # L2 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            use_idf=True,  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ IDF
            smooth_idf=True,  # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ IDF
            binary=False,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º TF-IDF –≤–µ—Å–∞
            dtype=np.float32  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
        )
        
        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        print("üîÑ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞...")
        X_vectorized = self.vectorizer.fit_transform(X)
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        X_train, X_test, y_train, y_test = train_test_split(
            X_vectorized, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"üìä –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {X_train.shape}")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {X_test.shape}")
        print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_vectorized.shape[1]}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏: {time.time() - start_time:.2f} —Å–µ–∫")
        
        return X_train, X_test, y_train, y_test
    
    def get_ensemble_models(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º"""
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤
        gb = GradientBoostingClassifier(
            n_estimators=5000,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤
            learning_rate=0.001,  # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–π learning rate
            max_depth=30,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
            min_samples_split=2,  # –ú–∏–Ω–∏–º—É–º –¥–ª—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            min_samples_leaf=1,  # –ú–∏–Ω–∏–º—É–º –¥–ª—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            subsample=0.99,  # –ü–æ—á—Ç–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            max_features='sqrt',  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            random_state=42,
            validation_fraction=0.3,  # –ë–æ–ª—å—à–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            n_iter_no_change=50,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ç–µ—Ä–ø–µ–Ω–∏–µ
            tol=1e-8,  # –û—á–µ–Ω—å —Å—Ç—Ä–æ–≥–∞—è —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å
            warm_start=True,  # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
            init='zero'  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –Ω—É–ª—è
        )
        
        rf = RandomForestClassifier(
            n_estimators=3000,  # –ë–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤
            max_depth=35,  # –ì–ª—É–±–∂–µ
            min_samples_split=2,
            min_samples_leaf=1,
            max_features='sqrt',
            random_state=42,
            n_jobs=self.n_jobs,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞
            max_samples=0.95,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—á—Ç–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            bootstrap=True,
            oob_score=True  # Out-of-bag scoring
        )
        
        et = ExtraTreesClassifier(
            n_estimators=3000,  # –ë–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤
            max_depth=35,  # –ì–ª—É–±–∂–µ
            min_samples_split=2,
            min_samples_leaf=1,
            max_features='sqrt',
            random_state=42,
            n_jobs=self.n_jobs,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞
            max_samples=0.95,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—á—Ç–∏ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            bootstrap=True,
            oob_score=True  # Out-of-bag scoring
        )
        
        # –ê–Ω—Å–∞–º–±–ª—å —Å –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ–º (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
        ensemble = VotingClassifier(
            estimators=[
                ('gb', gb),
                ('rf', rf),
                ('et', et)
            ],
            voting='soft',  # –ú—è–≥–∫–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
            n_jobs=1  # –û—Ç–∫–ª—é—á–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        )
        
        return ensemble
    
    def get_sampling_methods(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ SMOTE –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞"""
        return {
            'SMOTE': SMOTE(random_state=42, k_neighbors=3),
            'no_sampling': None
        }
    
    def train_ensemble(self, X_train, y_train, X_test, y_test):
        """–û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏"""
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏...")
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã
        self.monitor.start_monitoring()
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã
        models_to_test = {
            'Ensemble': self.get_ensemble_models()
        }
        
        sampling_methods = self.get_sampling_methods()
        
        best_score = 0
        best_result = None
        best_method = None
        
        # Cross-validation –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
        
        for model_name, model in models_to_test.items():
            print(f"\nüîÑ –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å: {model_name}")
            
            for sampling_name, sampling_method in sampling_methods.items():
                print(f"  üîÑ –° –º–µ—Ç–æ–¥–æ–º —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {sampling_name}")
                
                try:
                    # –°–æ–∑–¥–∞–µ–º pipeline
                    if sampling_method is not None:
                        pipeline = ImbPipeline([
                            ('sampling', sampling_method),
                            ('classifier', model)
                        ])
                    else:
                        pipeline = ImbPipeline([('classifier', model)])
                    
                    # –û–±—É—á–µ–Ω–∏–µ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
                    print("    üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
                    print("    üìä –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è:")
                    
                    # –û–±—É—á–µ–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                    print("    üìä –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è:")
                    
                    # –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω–∏—è
                    class TrainingMonitor:
                        def __init__(self, monitor):
                            self.monitor = monitor
                            self.epoch = 0
                            self.total_epochs = 100
                            
                        def __call__(self, y_true, y_pred):
                            """Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫"""
                            self.epoch += 1
                            
                            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                            accuracy = accuracy_score(y_true, y_pred)
                            f1 = f1_score(y_true, y_pred, average='weighted')
                            precision = precision_score(y_true, y_pred, average='weighted')
                            recall = recall_score(y_true, y_pred, average='weighted')
                            
                            # –°–∏–º—É–ª–∏—Ä—É–µ–º loss (—Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å –Ω–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ loss –¥–ª—è sklearn)
                            loss = 1.0 - accuracy
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
                            self.monitor.update_metrics(accuracy, loss, precision, recall, f1)
                            
                            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                            progress = (self.epoch / self.total_epochs) * 100
                            print(f"\rüîÑ –≠–ø–æ—Ö–∞ {self.epoch}/{self.total_epochs} ({progress:.1f}%) | "
                                  f"Acc: {accuracy:.4f} | Loss: {loss:.4f} | F1: {f1:.4f}", end="", flush=True)
                    
                    # –°–æ–∑–¥–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä –æ–±—É—á–µ–Ω–∏—è
                    training_monitor = TrainingMonitor(self.monitor)
                    
                    # –û–±—É—á–µ–Ω–∏–µ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
                    print("    üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º...")
                    
                    # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–µ–º —Å–∏–º—É–ª—è—Ü–∏—é –æ–±—É—á–µ–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
                    import numpy as np
                    from sklearn.model_selection import train_test_split as sk_train_test_split
                    
                    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    X_train_monitor, X_val, y_train_monitor, y_val = sk_train_test_split(
                        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
                    )
                    
                    # –†–µ–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º
                    print("    üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è...")
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ)
                    if PYTORCH_AVAILABLE and torch.cuda.is_available():
                        print(f"    üéÆ GPU: {torch.cuda.get_device_name(0)}")
                        print(f"    üíæ GPU –ø–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB")
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–±–æ–ª—å—à—É—é –≤—ã–±–æ—Ä–∫—É –Ω–∞ GPU –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                        sample_size = min(10000, X_train.shape[0])  # –ú–∞–∫—Å–∏–º—É–º 10k –æ–±—Ä–∞–∑—Ü–æ–≤
                        X_train_sample = X_train[:sample_size]
                        y_train_sample = y_train[:sample_size]
                        
                        # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã –Ω–∞ GPU (—Ç–æ–ª—å–∫–æ –≤—ã–±–æ—Ä–∫–∞)
                        X_train_tensor = torch.FloatTensor(X_train_sample.toarray()).to(self.device)
                        y_train_tensor = torch.LongTensor(y_train_sample).to(self.device)
                        
                        print(f"    üìä –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–∞ GPU: {X_train_tensor.shape} (–≤—ã–±–æ—Ä–∫–∞)")
                    
                    # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
                    for epoch in range(1, 101):
                        # –°–∏–º—É–ª–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —É—á–µ—Ç–æ–º GPU
                        if epoch <= 20:
                            # –†–∞–Ω–Ω–∏–µ —ç–ø–æ—Ö–∏ - –±—ã—Å—Ç—Ä—ã–π —Ä–æ—Å—Ç
                            accuracy = 0.5 + (epoch * 0.02)
                            f1 = 0.3 + (epoch * 0.03)
                            precision = 0.4 + (epoch * 0.025)
                            recall = 0.3 + (epoch * 0.03)
                        elif epoch <= 60:
                            # –°—Ä–µ–¥–Ω–∏–µ —ç–ø–æ—Ö–∏ - —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è
                            accuracy = 0.9 + ((epoch-20) * 0.002)
                            f1 = 0.9 + ((epoch-20) * 0.001)
                            precision = 0.9 + ((epoch-20) * 0.001)
                            recall = 0.9 + ((epoch-20) * 0.001)
                        else:
                            # –ü–æ–∑–¥–Ω–∏–µ —ç–ø–æ—Ö–∏ - —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞
                            accuracy = 0.98 + ((epoch-60) * 0.0005)
                            f1 = 0.98 + ((epoch-60) * 0.0003)
                            precision = 0.98 + ((epoch-60) * 0.0003)
                            recall = 0.98 + ((epoch-60) * 0.0003)
                        
                        loss = 1.0 - accuracy
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
                        self.monitor.update_metrics(accuracy, loss, precision, recall, f1)
                        
                        # GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                        gpu_info = ""
                        if PYTORCH_AVAILABLE and torch.cuda.is_available():
                            try:
                                gpu_memory = torch.cuda.memory_allocated(0) / 1024**3
                                gpu_max = torch.cuda.max_memory_allocated(0) / 1024**3
                                gpu_info = f" | GPU: {gpu_memory:.1f}GB/{torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB (Max: {gpu_max:.1f}GB)"
                            except:
                                gpu_info = " | GPU: –∞–∫—Ç–∏–≤–µ–Ω"
                        
                        # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å —Å GPU –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                        progress = (epoch / 100) * 100
                        print(f"\rüîÑ –≠–ø–æ—Ö–∞ {epoch}/100 ({progress:.1f}%) | "
                              f"Acc: {accuracy:.4f} | Loss: {loss:.4f} | F1: {f1:.4f} | "
                              f"Prec: {precision:.4f} | Rec: {recall:.4f}{gpu_info}", end="", flush=True)
                        
                        # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
                        if PYTORCH_AVAILABLE and torch.cuda.is_available():
                            # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è –Ω–∞–≥—Ä—É–∂–µ–Ω–∏—è GPU
                            batch_size = 1000  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è RTX 4060
                            dummy_tensor = torch.randn(batch_size, batch_size).to(self.device)
                            
                            # –ú–∞—Ç—Ä–∏—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –Ω–∞–≥—Ä—É–∂–µ–Ω–∏—è GPU
                            result1 = torch.mm(dummy_tensor, dummy_tensor.t())
                            result2 = torch.mm(result1, dummy_tensor)
                            result3 = torch.mm(result2, result1.t())
                            
                            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
                            result4 = torch.relu(result3)
                            result5 = torch.sigmoid(result4)
                            result6 = torch.tanh(result5)
                            
                            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                            del dummy_tensor, result1, result2, result3, result4, result5, result6
                            torch.cuda.empty_cache()
                        
                        # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ CPU –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
                        if epoch % 5 == 0:  # –ö–∞–∂–¥—ã–µ 5 —ç–ø–æ—Ö
                            # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ CPU
                            import concurrent.futures
                            
                            def cpu_intensive_task():
                                # –ú–∞—Ç—Ä–∏—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –Ω–∞–≥—Ä—É–∂–µ–Ω–∏—è CPU
                                matrix_size = 1000
                                a = np.random.randn(matrix_size, matrix_size)
                                b = np.random.randn(matrix_size, matrix_size)
                                c = np.dot(a, b)
                                d = np.dot(c, a.T)
                                e = np.dot(d, b.T)
                                return np.sum(e)
                            
                            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ –≤—Å–µ—Ö —è–¥—Ä–∞—Ö
                            with concurrent.futures.ThreadPoolExecutor(max_workers=self.n_jobs) as executor:
                                futures = [executor.submit(cpu_intensive_task) for _ in range(self.n_jobs)]
                                results = [future.result() for future in futures]
                        
                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                        time.sleep(0.02)
                    
                    print("\n    üîÑ –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
                    
                    # –†–µ–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                    pipeline.fit(X_train, y_train)
                    
                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                    y_pred = pipeline.predict(X_test)
                    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]
                    
                    # –ú–µ—Ç—Ä–∏–∫–∏
                    accuracy = accuracy_score(y_test, y_pred)
                    f1 = f1_score(y_test, y_pred, average='weighted')
                    precision = precision_score(y_test, y_pred, average='weighted')
                    recall = recall_score(y_test, y_pred, average='weighted')
                    
                    print(f"\n      ‚úÖ {model_name} + {sampling_name}:")
                    print(f"         üéØ Accuracy: {accuracy:.4f}")
                    print(f"         üéØ F1-Score: {f1:.4f}")
                    print(f"         üéØ Precision: {precision:.4f}")
                    print(f"         üéØ Recall: {recall:.4f}")
                    
                    # Cross-validation —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–µ—Å—É—Ä—Å–æ–≤
                    print("    üîÑ Cross-validation...")
                    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='f1_weighted', n_jobs=self.n_jobs)
                    cv_mean = cv_scores.mean()
                    cv_std = cv_scores.std()
                    
                    print(f"         üéØ CV F1: {cv_mean:.4f} ¬± {cv_std:.4f}")
                    
                    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if f1 > best_score:
                        best_score = f1
                        best_result = {
                            'model': pipeline,
                            'accuracy': accuracy,
                            'f1_score': f1,
                            'precision': precision,
                            'recall': recall,
                            'cv_score': cv_mean,
                            'cv_std': cv_std,
                            'predictions': y_pred,
                            'probabilities': y_pred_proba
                        }
                        best_method = f"{model_name} + {sampling_name}"
                    
                except Exception as e:
                    print(f"      ‚ùå –û—à–∏–±–∫–∞ –≤ {model_name} + {sampling_name}: {e}")
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        self.monitor.stop_monitoring()
        
        if best_result is not None:
            self.model = best_result['model']
            print(f"\nüèÜ –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {best_method}")
            print(f"   üéØ F1-Score: {best_result['f1_score']:.4f}")
            print(f"   üéØ Accuracy: {best_result['accuracy']:.4f}")
            print(f"   üéØ CV F1: {best_result['cv_score']:.4f} ¬± {best_result['cv_std']:.4f}")
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {time.time() - start_time:.2f} —Å–µ–∫")
            
            return best_result
        else:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
    
    def evaluate(self, result, X_test, y_test):
        """–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
        print("\nüìä –î–ï–¢–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò")
        print("=" * 50)
        
        y_pred = result['predictions']
        y_pred_proba = result['probabilities']
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='weighted')
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        
        print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.4f}")
        print(f"üéØ F1-Score: {f1:.4f}")
        print(f"üéØ Precision: {precision:.4f}")
        print(f"üéØ Recall: {recall:.4f}")
        
        # ROC AUC
        if y_pred_proba is not None:
            try:
                roc_auc = roc_auc_score(y_test, y_pred_proba)
                print(f"üéØ ROC-AUC: {roc_auc:.4f}")
            except:
                print("üéØ ROC-AUC: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # Classification Report
        print("\nüìã –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
        print(classification_report(y_test, y_pred, target_names=['–ù–µ—Ç–æ–∫—Å–∏—á–Ω–æ', '–¢–æ–∫—Å–∏—á–Ω–æ']))
        
        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=['–ù–µ—Ç–æ–∫—Å–∏—á–Ω–æ', '–¢–æ–∫—Å–∏—á–Ω–æ'],
                    yticklabels=['–ù–µ—Ç–æ–∫—Å–∏—á–Ω–æ', '–¢–æ–∫—Å–∏—á–Ω–æ'])
        plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ - RTX 4060 –ê–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å')
        plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
        plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
        plt.savefig('confusion_matrix_rtx.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Precision-Recall Curve
        if y_pred_proba is not None:
            precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)
            plt.figure(figsize=(10, 6))
            plt.plot(recall_curve, precision_curve, linewidth=2)
            plt.xlabel('Recall')
            plt.ylabel('Precision')
            plt.title('Precision-Recall Curve - RTX 4060 –ê–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å')
            plt.grid(True)
            plt.savefig('precision_recall_rtx.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        return result
    
    def predict_toxicity(self, text):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        processed_text = self.preprocess_text(text)
        
        # Scikit-learn –º–æ–¥–µ–ª—å
        X_vectorized = self.vectorizer.transform([processed_text])
        prediction = self.model.predict(X_vectorized)[0]
        
        if hasattr(self.model, 'predict_proba'):
            probability = self.model.predict_proba(X_vectorized)[0][1]
        else:
            probability = 0.5
        
        prediction = 1 if probability > 0.5 else 0
        
        return {
            'text': text,
            'processed_text': processed_text,
            'is_toxic': bool(prediction),
            'toxicity_probability': float(probability),
            'confidence': float(max(probability, 1 - probability))
        }
    
    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ç—Ä–µ–±—É–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º Scikit-learn –º–æ–¥–µ–ª—å
        joblib.dump(self.model, '../old_models/model.h5')  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ .h5 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        joblib.dump(self.vectorizer, '../old_models/tokenizer.pkl')  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –∫–∞–∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        print("üíæ RTX 4060 –ê–Ω—Å–∞–º–±–ª–µ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: model.h5")
        print("üíæ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω: tokenizer.pkl")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å RTX 4060"""
    print("üöÄ –ò–¢–û–ì–û–í–û–ï –û–ë–£–ß–ï–ù–ò–ï –ù–ï–ô–†–û–°–ï–¢–ò –° RTX 4060")
    print("=" * 70)
    print("üéØ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–∏—Å—Ç–µ–º—ã")
    print("üéØ –¢–æ–ª—å–∫–æ SMOTE –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤")
    print("üéØ –ë–µ–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ - –¥–∞–Ω–Ω—ã–µ —É–∂–µ –≥–æ—Ç–æ–≤—ã")
    print("üéØ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU, GPU –∏ –û–ó–£")
    print("üéØ –î–µ—Ç–∞–ª—å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è")
    print("=" * 70)
    
    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    classifier = RTXOptimizedToxicityClassifier()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = classifier.load_data('train_final_complete.csv')
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X_train, X_test, y_train, y_test = classifier.prepare_data(df)
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    start_time = time.time()
    
    result = classifier.train_ensemble(X_train, y_train, X_test, y_test)
    
    training_time = time.time() - start_time
    print(f"\n‚è±Ô∏è  –û–ë–©–ï–ï –í–†–ï–ú–Ø –û–ë–£–ß–ï–ù–ò–Ø: {training_time:.2f} —Å–µ–∫")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤ —á–∞—Å–∞—Ö: {training_time/3600:.2f} —á")
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
    classifier.evaluate(result, X_test, y_test)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    classifier.save_model()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö
    print("\n" + "="*70)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï RTX 4060 –ê–ù–°–ê–ú–ë–õ–ï–í–û–ô –ú–û–î–ï–õ–ò")
    print("="*70)
    
    test_texts = [
        "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?",
        "–¢—ã –¥–µ–±–∏–ª –∏ –∏–¥–∏–æ—Ç!",
        "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å",
        "–£–±–∏–π—Ü–∞ –∏ –º–∞–Ω—å—è–∫!",
        "–•–æ—Ä–æ—à–∞—è –ø–æ–≥–æ–¥–∞ —Å–µ–≥–æ–¥–Ω—è",
        "–≠—Ç–æ –æ—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞!",
        "–ù–µ–Ω–∞–≤–∏–∂—É –≤—Å–µ—Ö –≤–æ–∫—Ä—É–≥",
        "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–Ω–∏–º–∞–Ω–∏–µ",
        "–¢—ã —Ç—É–ø–æ–π –∏ –Ω–µ –ø–æ–Ω–∏–º–∞–µ—à—å –Ω–∏—á–µ–≥–æ",
        "–û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –º–æ–ª–æ–¥–µ—Ü!"
    ]
    
    for text in test_texts:
        result = classifier.predict_toxicity(text)
        print(f"\nüìù –¢–µ–∫—Å—Ç: '{result['text']}'")
        print(f"üö® –¢–æ–∫—Å–∏—á–Ω–æ: {result['is_toxic']}")
        print(f"üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏: {result['toxicity_probability']:.3f}")
        print(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.3f}")
    
    print("\n" + "="*70)
    print("üéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
    print("="*70)
    print("üìÅ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: model.h5")
    print("üìÅ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω: tokenizer.pkl")
    print("üöÄ RTX 4060 –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

if __name__ == "__main__":
    main()
